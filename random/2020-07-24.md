# 2020-07-24

|Time (UTC)|Icon|Name|Message|
|---|---|---|---|
|12:42|![](https://secure.gravatar.com/avatar/3f82b853a23d9a6d1ce612d83f3a3a54.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0008-72.png)|Atsushi Shimono|fyi.<br><https://github.com/w3c/publishingcg/issues/5><br><blockquote>*The Problem*<br><br>Accessibility is really important to me, but I will probably never have the  <br>funds to provide audio versions of what Pipfrosch Press is publishing. Some of  <br>my planned publications will have frequent content updates rather than just  <br>being static publications. For example, my planned field guide to Contra Costa  <br>County will likely never ever be finished, with new species accounts added every  <br>year and existing species accounts modified with some frequency.<br><br>For the print-disabled user, Text To Speech (TTS) Synthesis will be how they  <br>access the content.<br><br>ePub currently has two different mechanisms for providing pronunciation hints to  <br>TTS Synthesizers, PLS and SSML.<br><br>When there is only one way to pronounce a grapheme, PLS is the better option as  <br>it allows a single document that can be updated as needed, either by the ePub  <br>publisher or by a school / library as needed. PLS also supports multiple  <br>phonetic alphabets at the same time.<br><br>Where there are multiple ways to pronounce a grapheme, SSML is better because it  <br>allows the specific pronunciation to be specified for the use case of the  <br>grapheme. However SSML only allows a single phonetic alphabet to be specified.<br><br>Unfortunately neither solution allows for regional pronunciation variations.<br><br>Even though both PLS and SSML have been in the ePub standard for some time, they  <br>are not implemented by the vast majority of ePub viewers. I have _heard_ of one  <br>custom viewer used by a Japanese school district that implements them, but I was  <br>not able to confirm it.<br><br>I recommend a new solution, a single solution that covers both use cases as well  <br>as allowing for region-specific pronunciations and allows for as many different  <br>phonetic alphabets as the ePub publisher knows about.<br><br>This solution does not have to be restricted to ePub but could work with any  <br>digital publishing format, including websites and PDF (though perhaps not as an  <br>embedded solution within PDF, I do not know).<br><br>This probably should only become part of the ePub standard if Apple, Google, and  <br>EDRLab are on board and are committed to implementing it in their software. How  <br>to get them on-board I have no clue, I have social anxiety and as a result do  <br>not often portray confidence when proposing solutions, even were I to find a way  <br>to get their ear, and unfortunately when proposing something without an  <br>appearance of confidence, those with the power to implement can not see past the  <br>presentation to see the value of what is being presented.<br><br>This solution probably needs to be adjusted by those with far more experience in  <br>the issues related to TTS Synthesis than I have, but this solution should be  <br>fairly easy to extend as is.<br><br>It probably needs to be yet another W3C project for experts in the field to  <br>refine. It is my hope that someone who knows how to work the system to make  <br>things happen sees the value in this and runs with it. I do not need any credit  <br>if that happens, I just want a solution that works well as I publish my ePubs. A  <br>solution that brings my ePubs to print-disabled users enjoyment rather than  <br>frustration.<br><br>*JSON Pronunciation Library*<br><br>Example JSON file attached.<br><br>The format for the JSON Pronunciation Library shall be JSON. JSON was chosen for  <br>the ease of which valid JSON files may be generated from a number of programming  <br>languages from database queries, including Python and PHP. I am personally a big  <br>fan of XML but this I think should be JSON.<br><br>The character set for the JSON pronunciation library will be UTF-8.<br><br>The first definition in a the JSON pronunciation library shall be `lang` and  <br>either be assigned a string value of a BCP-47 language code or a list of BCP-47  <br>language codes.<br><br>Examples:<br><br><pre>"lang": "en"<br>"lang": "en-US", "en-GB"<br></pre><br><br>In most cases, the generic language is to be preferred over a localized  <br>language.<br><br>The text to speech synthesizer will only use a JSON Pronunciation Library that  <br>matches the current specified language within the (X)HTML document. For example,  <br>if the current document is specified as "en-US" then a JSON Pronunciation  <br>Library with `lang="es"` would not be used for pronunciations except for a  <br>string within a node labeled with the XML attribute `lang="es"`. This is to  <br>avoid collisions where languages that share the same alphabet have words with  <br>an identical grapheme but are pronounced quite differently, allowing the Text to  <br>Speech Synthesizer to use its own pronunciation algorithms in the event that an  <br>entry exists for one language but does not exist for the language specified for  <br>the string being read.<br><br>*Pronunciation Context Dictionary*<br><br>The JSON Pronunciation Library will have at least one context dictionary named  <br>`default` but may have additional context dictionaries. In the example  <br>JSON Pronunciation Library, additional context dictionaries named `taxonomy`  <br>(for taxonomy names) and `proper` (for proper names) are provided.<br><br>The `default` context dictionary is to be used by TTS synthesizers either when  <br>a context is not specified or when the grapheme is not found in the specified  <br>context dictionary.<br><br>Each context dictionary will have a list named `entries`<br><br>*grapheme entry*<br><br>Each context dictionary entry list item must have a `grapheme` definition that  <br>specifies either a string or a list of strings. Examples:<br><br><pre>"grapheme": "job"<br><br>"grapheme": ["estivate", "aestivate", "æstivate"]<br></pre><br><br>The specified `grapheme` should not be interpreted as case sensitive.<br><br>In cases where only one pronunciation for that grapheme is provided, one of more  <br>phonetic alphabets with the corresponding phoneme can be specified. An example  <br>that provides a phoneme for both `ipa` and `x-sampa`:<br><br><pre>{<br>  "grapheme": ["estivate", "aestivate", "æstivate"],<br>  "ipa": "ˈɛstɪˌveɪt",<br>  "x-sampa": "EstI%veIt"<br>}<br></pre><br><br>The text to speech synthesizer can then pick the alphabet it has the best  <br>support for and use that phoneme to pronounce the grapheme.<br><br>*speechpart*<br><br>In some languages, the same grapheme may have a different pronunciation  <br>depending upon the part of speech it is used in. For example, the grapheme  <br>`wind` in English is pronounced differently---and has a different  <br>meaning---depending upon if it is noun (or adjective) or a verb.<br><br>In those cases, a `speechpart` can be defined and the (X)HTML author should  <br>specify the speech part with a span element. The `speechpart` will then hold  <br>either the phoneme or regional variation phoneme. An example:<br><br><pre>{<br>  "grapheme": "wind",<br>  "speechpart": {<br>    "noun" : {<br>      "ipa": "wɪnd",<br>      "x-sampa": "wInd"  <br>    },<br>    "verb" : {<br>      "ipa": "waɪnd",<br>      "x-sampa": "waInd"<br>    }<br>  }<br>}<br></pre><br><br>When the `speechpart` is not specified by the (X)HTML the text to speech  <br>synthesizer _may_ attempt to detect the speech part based upon a grammatical  <br>parsing of the sentence, as some seem to do already, but best practice  <br>should be for the (X)HTML author to specify the `speechpart` as an XML  <br>attribute to a span element around the grapheme.<br><br>When the `speechpart` is not determined or does not match a specified  <br>`speechpart` then the first `speechpart` should be used. In the above  <br>example, with the sentence "That is a beautiful wind turbine" wind is an  <br>adjective but since a pronunciation for the grapheme `wind` as an  <br>adjective is not specified, the noun phoneme for `wind` would be used since it  <br>is the first defined `speechpart`.<br><br>*Regional Pronunciation*<br><br>Within the same language, sometimes a grapheme has a different pronunciation  <br>depending upon political borders or cultural grouping.<br><br>An example of this is the grapheme `vase`. It seems to be pronounced differently  <br>in America than in Great Britain than in Australia, though I am not positive  <br>about the latter.<br><br>In those cases, a list of phonemes for the grapheme may be provided. For example:<br><br>```<br>{<br>  "grapheme": "vase",<br>  "languages" : [<br>    {<br>      "lang": "en-US",<br>      "ipa": "veɪs",<br>      "x-sampa": "veIs"<br> …</blockquote>|
